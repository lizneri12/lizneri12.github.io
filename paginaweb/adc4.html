<!DOCTYPE html>
        <html lang="en">

   
        <body bgcolor="cc0000">
        <marquee direccion="left"> <font face="arial blach" size="25" color="black">
        Arquitectura De Computadoras </font></marquee>
        <hr>
  
         <header class="unidades">
        <font face="arial blach" size="25" color="black">
        <p> <font class="subtitulo"> <a href="adc.html">Unidad 1</a> &nbsp; &nbsp; <a href="adc2.html">Unidad 2</a>  &nbsp; &nbsp; <a href="adc3.html">Unidad 3</a>  &nbsp; 
        &nbsp;  <a href="adc4.html">Unidad 4 </a>  &nbsp;  <a href="Practicas.html"> Practicas</a> &nbsp;</a></font> </p>
        </header>


        <section>
        <nav>
        <ul>

        <body>
        <body bgcolor="cc0000">
        <font face="arial blach" size="4" color="black">

        <a href="#4.1"><li>4.1 Aspectos Básicos de la Computación Paralela</li></a>
                <a href="#4.2"><li>4.2 Tipos de Computación Paralela</li></a>
                <ul>
                    <a href="#4.2.2"><li class="indt">4.2.2 Arquitectura de Computadoras Secuenciales</li></a>
                    <a href="#4.2.2.1"><li class="indt">4.2.2.1 Taxonomía de Flynn</li></a>
                    <a href="#4.2.3"><li class="indt">4.2.3 Organización de Direcciones de Memoria<?li></a>
                </ul>
                <a href="#4.3"><li>4.3 Sistemas de Memoria Compartida</li></a>
                <ul>
                    <a href="#4.3.1"><li class="indt">4.3.1 Redes de Interconexión Dinámicas ó Indirectas</li></a>
                    <ul>
                        <a href="#4.3.1.1"><li class="indt2">4.3.1.1 Redes de Medio Compartido</li></a>
                        <a href="#4.3.1.2"><li class="indt2">4.3.1.2 Redes Conmutadas</li></a>
                    </ul>
                </ul>
                <a href="#4.4"><li>4.4 Sistemas de Memoria Distribuida: Multiprocesadores</li></a>
                <ul>
                    <a href="#4.4.1"><li class="indt">4.4.1 Redes de Interconexión Estáticas</li></a>
                </ul>
                <a href="#4.5"><li>4.5 Casos de Estudio</li></a>
                </ul>
            </ul>
        </nav>

        <article>
            <h1><font class="title"> <center> Unidad 4 </center></font></h1>
            <p> <br> </p>
            <h2 id="4.1">4.1 Aspectos Básicos de la Computación Paralela</h2> <hr>
            <p class="text">La computación paralela es una técnica de procesamiento de información que se basa en la utilización de múltiples procesadores para llevar a cabo 
            una tarea en paralelo, en lugar de utilizar un solo procesador. Esta técnica permite mejorar significativamente la velocidad y eficiencia de los cálculos y 
            análisis de datos en la computadora.</p><p><br></p>
            <h4> <i>Sistemas de procesamiento paralelo </i> </h4>
            <p class="text">Los sistemas de procesamiento paralelo se pueden clasificar en dos categorías: simétricos y asíncronos. Uno donde todos los procesadores 
            comparten la misma memoria, y otro donde cada procesador tiene su propia memoria.</p><p><br></p>
            <h4> <i> Herramientas de computación en paralelo</i> </h4>
            <p class="text">Las herramientas de computación en paralelo son programas y bibliotecas que se utilizan para programar y ejecutar aplicaciones en sistemas 
            paralelos, de forma que podamos sacarle el máximo provecho a estos. Un ejemplo de esto es la herramienta CUDA desarrollada por Nvidia, la cual 
            permite que aplicaciones aprovechen el procesamiento paralelo para el procesamiento de gráficos, usando la GPU como un coprocesador usando paralelamente sus núcleos.
            </p><p><br></p>

            <h2 id="4.2">4.2 Tipos de Computación Paralela</h2> <hr>
            <h4> <i>clasificacion</i> </h4>
            <p class="text"><b>Tipos:</b> <ul class="indt"><li>Un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) 
            en el mismo chip.</liUn multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a 
            través de un bus.></li><li>Un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden 
            considerarse como un solo equipo.</li><li>Tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores</li><li>La computación distribuida es la 
            forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado.
            </li><li>Debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación.</li></ul> </p><p><br></p>
            <p align="center"><img src="http://ferestrepoca.github.io/paradigmas-de-programacion/paralela/paralela_teoria/images/cvsa.png"><br></p>

            <h1 id="4.2.2">4.2.2 Arquitectura de Computadoras Secuenciales</h1>
            <p class="text">Las computadoras secuenciales se basan en el modelo introducido por John Von Neumann, la cual consiste en:</b> <ul class="indt"><li>Una Unidad 
            Central de Procesamiento(CPU)</li><li>Memoria Principal para almacenar información</li><li>Bus donde fluyan los datos</li>Mecanismo de 
            sincronización</li></ul></p><p><br></p>
            <h4> <i>segmentación de instrucciones Pipeline</i> </h4>
            <p class="text">Por las limitaciones que este tiene se han desarrollado algunas estrategias para aumentar el rendimiento.La más conocida es la segmentación
            de instrucciones Pipeline que consiste en llevar a la cola de instrucciones la siguiente instrucción que se ejecutará</p><p><br></p>
            <h4> <i>Tipos de sistemas secuenciales</i> </h4>
            <p class="text">En estos sistemas, los valores de las salidas, en un momento dado, no dependen exclusivamente de los valores de las entradas en dicho momento, 
            sino también de los valores anteriores.</p><p><br></p>
            <h4> <i>Biestable</i> </h4>
            <p class="text">Es un multivibrador capaz de permanecer en uno de dos estados posibles durante un tiempo indefinido en ausencia de perturbaciones. Esta característica 
            es ampliamente utilizada en electrónica digital para memorizar información. El paso de un estado a otro se realiza variando sus entradas.</p><p><br></p>
            <p class="text">La mayoría de estos sistemas están gobernados por señales de reloj a los cuales se los denomina sincronos. Pero al contrario a todos ellos que no son 
            gobernados por éste, se les conoce como asíncronos.Estos pueden encontrarse en forma de Circuito integrado (Contador) o como estructuras en sistemas programados</p><p><br></p>
            <p class="text">pueden encontrarse en forma de Circuito integrado (Contador) o como estructuras en sistemas programados (Registros de desplazamiento):</b> <ul class="indt">
            <li> Contador: Circuito secuencial construido a partir de biestable y puertas lógicas capaz de almacenar y contar los impulsos que recibe en la entrada destinada 
            a tal efecto, asimismo también actúa como divisor de frecuencia.</li><li>Registros de desplazamiento: Consistente en una serie de biestables, generalmente de tipo D, 
            conectados en cascada, que basculan de forma sincrénica con la misma sefial de reloj.</li></ul></p><p><br></p>

            <h1 id="4.2.2.1">4.2.2.1 Taxonomía de Flynn</h1>
            <p class="text">Probablemente la clasificación más popular de computadores sea la clasificación de Flynn. Esta taxonomía de las arquitecturas está basada en 
            la clasificación atendiendo al flujo de datos e instrucciones en un sistema. Un flujo de instrucciones es el conjunto de instrucciones secuenciales que son 
            ejecutadas por un único procesador, y un flujo de datos es el flujo secuencial de datos requeridos por el flujo de instrucciones. </p><p><br></p>
            <p align="center"><img src="https://img-aws.ehowcdn.com/700x400/photos.demandstudios.com/197/59/fotolia.jpg"><br></p>
            <p class="text">Se basa en el número de instrucciones y de la secuencia de datos que la computadora utiliza para procesar información, Puede haber 
            secuencias de instrucciones sencillas o múltiples y secuencias de datos sencillas o múltiples</p><p><br></p>
            <h4> <i>Una instruccion, un dato (SISD) - Single Instruction, Single Data.</i> </h4>
            <p class="text">Se refiere a una arquitectura computacional en la que un Único procesador ejecuta un solo flujo de instrucciones, para operar sobre datos almacenados 
            en una Única memoria.Se corresponde con la arquitectura de Von Neumann.</p><p><br></p>
            <li> caracteristicas:</b> <ul class="indt"></li><li>La CPU procesa Unicamente una instrucción por cada ciclo de reloj</li><li>Unicamente un dato es procesado en cada 
            ciclo de reloj.</li><liEs el modelo mas antiguo de computadora y el mas extendido.</li></ul></p><p><br></p>
            <h4> <i>Multiples instrucciones, un dato (MISD) -Multiple Instruction, Single Data,</i> </h4>
            <p class="text">Donde muchas unidades funcionales realizan diferentes operaciones en los mismos datos. Las arquitecturas segmentadas pertenecen a este tipo.
            </p><p><br></p>
            <li> caracteristicas:</b> <ul class="indt"></li><li>Cada unidad ejecuta una instrucción distinta.</li><li>Cada unidad procesa el mismo dato</li><li>Aplicación muy 
            limitada en la vida real.</li></ul></p><p><br></p>
            <h4> <i>Una instrucción, múltiples datos (SIMD) - Single Instruction, Multiple Data.</i> </h4>
            <p class="text">Es una técnica empleada para conseguir paralelismo a nivel de datos, consisten en instrucciones que aplican una misma operación sobre 
            un conjunto más o menos grande de datos.</p><p><br></p>
            <li> caracteristicas:</b> <ul class="indt"></li><li>Todas las unidades ejecutan la misma instrucción.</li><li> Cada unidad procesa un dato distinto.
            </li><li>Todas las unidades operan simultáneamente.</li></ul></p><p><br></p>

             <h1 id="4.2.3">4.2.3 Organización de Direcciones de Memoria</h1>
            <p class="text">Organización lógica:<br> Los programas a menudo están organizados en módulos, algunos de los cuales pueden ser compartidos por diferentes 
            programas. La gestión de memoria es responsable de manejar esta organización lógica, que se contrapone al espacio de direcciones físicas lineales. Una forma de lograrlo 
            es mediante la segmentación de memoria.</p><p><br></p>
            <p align="center"><img src="https://img-aws.ehowcdn.com/750x500/photos.demandstudios.com/197/59/fotolia_256152_XS.jpg"><br></p>
            <p class="text">Organización física:<br> La memoria suele dividirse en un almacenamiento primario de alta velocidad y uno secundario de menor velocidad. La 
            gestión de memoria del sistema operativo se ocupa de trasladar la información entre estos dos niveles de memoria.</p><p><br></p>
            <p class="text">Las direcciones de memoria se organizan en bloques o segmentos de memoria, cada uno con una dirección base y un tamaño determinado. Las direcciones de 
            memoria se representan como números enteros que indican la posición en la memoria donde se encuentra un dato o una instrucción.</p><p><br></p>
            <p class="text">En los sistemas de memoria de acceso aleatorio (RAM), las direcciones de memoria se organizan en una matriz de celdas de memoria, donde cada celda 
            se puede  acceder directamente mediante su dirección. En los sistemas de memoria caché, la organización de direcciones de memoria se utiliza para gestionar la caché y 
            optimizar el acceso a los datos.</p><p><br></p>
            <p class="text">Hay dos tipos de organización de direcciones de memoria: la organización de direcciones de memoria contiguas y la organización de direcciones de 
            memoria no contiguas.</p><p><br></p>
            <p class="text">La organización de direcciones de memoria contiguas es aquella en la que las celdas de memoria se organizan de forma consecutiva en la memoria. En este 
            tipo de organización, la dirección de memoria de una celda se puede calcular sumando la dirección de la celda anterior y el tamaño de la celda actual.</p><p><br></p>
            <p class="text">La organización de direcciones de memoria no contiguas es aquella en la que las celdas de memoria se organizan en cualquier lugar de la memoria, sin 
            ningún patrón predecible. En este tipo de organización, la dirección de memoria se asigna a cada celda de forma independiente.</p><p><br></p>
            <p class="text">La organización de direcciones de memoria contiguas es más eficiente que la organización de direcciones de memoria no contiguas, ya que permite un 
            acceso más rápido a la memoria.</p><p><br></p>
            <p class="text">La organización de direcciones de memoria es fundamental para el funcionamiento de los sistemas informáticos, ya que garantiza que los datos se 
            almacenen y recuperen de forma eficiente y precisa. Los ingenieros de software y hardware deben comprender la organización de direcciones de memoria para diseñar 
            sistemas que sean eficientes y confiables.</p><p><br></p>

            <h2 id="4.3">4.3 Sistemas de Memoria Compartida</h2> <hr>
            <p class="text">como funciona:<ul class="indt"> <li>La memoria compartida funciona permitiendo que múltiples procesos accedan a la misma región de 
            memoria. Esto significa que cada proceso puede leer y escribir en la misma sección de memoria, lo que les permite compartir información y comunicarse entre sí de 
            manera  eficiente.</li><li>Para implementar la memoria compartida, el sistema operativo proporciona una sección de memoria que se puede asignar a varios procesos. 
            Cuando un proceso desea acceder a la memoria compartida, debe unirse a ella y obtener un puntero a la región de memoria compartida. A partir de ahí, el 
            proceso puede leer y escribir datos en la misma sección de memoria.</ul><li>Para evitar problemas de concurrencia, como la posibilidad de que dos procesos accedan a 
            la misma región de memoria al mismo tiempo, se utilizan técnicas de sincronización para coordinar el acceso a la memoria compartida. Las técnicas de sincronización más 
            comunes son los semáforos y los mutex. Estos son objetos que actúan como candados, permitiendo que un solo proceso acceda a la memoria compartida en un momento dado. 
            Por ejemplo, cuando un proceso desea escribir en la memoria compartida, puede solicitar el candado y obtener acceso exclusivo a la región de memoria. Otros procesos que 
            deseen leer o escribir deben esperar hasta que el candado se libere.</p><p><br></p>
            <p class="text">En informática, la memoria compartida es aquel tipo de memoria que puede ser accedida por múltiples programas, ya sea para comunicarse entre ellos o 
            para evitar copias redundantes. La memoria compartida es un modo eficaz de pasar datos entre aplicaciones. Dependiendo del contexto, los programas pueden ejecutarse 
            en un mismo procesador o en procesadores separados. La memoria usada entre dos hilos de ejecución dentro de un mismo programa se conoce también como memoria compartida.
            </p><p><br></p>
            <h4> <i>hardware</i> </h4>
            <p class="text">En hardware, la memoria compartida se refiere a una configuración de hardware en la que varios componentes comparten un área de memoria común en 
            lugar de tener su propia memoria dedicada. Esto permite a los componentes compartir información y datos de manera más eficiente, en lugar de tener que 
            transferir datos a través de canales de comunicación más lentos.</p><p><br></p>

            <h1 id="4.3.1">4.3.1 Redes de Interconexión Dinámicas ó Indirectas</h1>
            <p class="text"Las redes de interconexión dinámicas son una tecnología emergente que permite la conexión y comunicación entre diferentes sistemas informáticos en 
            tiempo real.Estas redes permiten la integración de diferentes plataformas y servicios, lo que aumenta la eficiencia y reduce los tiempos de respuesta en los 
            procesos empresariales.</p><p><br></p>
            <p class="text">Red Dinamica<ul class="indt"><li>Una red dinámica es una red cuya topología puede variar durante el cursó de la ejecución de un programa paralelo o 
            entre dos ejecuciones de programas. La red está constituida por elementos materiales específicos, llamados Conmutadores o switches</li></ul> </p><p><br></p>
            <p class="text">Red Indirecta:<ul class="indt"><li>Las redes indirectas también pueden modelarse con un grafo donde n es un conjunto dé switches y c es el conjunto 
            de enlaces unidireccionales o bidireccionales entre switches. Para el análisis de la mayoría de propiedades, no es necesario incluir explícitamente los 
            nodos de procesamiento en el grafo. Aunque las redes indirectas pueden modelarse de forma similar a las directas existen algunas diferencias entre ellas</li></ul> 
            </p><p><br></p>
            <h4> <i>Redes Dinamicas</i> </h4>
            <p class="text">Redes Dinamicas Las redes de interconexión dinámicas son convenientes en los casos en que se desee una red de propósito general ya que son 
            fácilmente reconfigurables. También por eso, este tipo de redes facilitan mucho la escalabilidad. En general, las redes dinámicas necesitan de elementos
            de conexión específicos como pueden ser árbitros de bus, conmutadores, etc.</p><p><br></p>
            <h4> <i>Protocolo de arbitraje distribuido</i> </h4>
            <p class="text">La responsabilidad del arbitraje se distribuye por los diferentes procesadores conectados al bus.</p><p><br></p>
            <h4> <i>Caracteristicas</i> </h4>
            <p class="text">Las redes de interconexión dinámicas se caracterizan por su flexibilidad y escalabilidad, lo que les permite adaptarse a diferentes entornos y 
            necesidades empresariales. Además, estas redes cuentan con herramientas de análisis y monitoreo que permiten identificar problemas y mejorar la eficiencia en tiempo 
            real, lo que las convierte en una herramienta esencial para la transformación digital de las empresas.</p><p><br></p>

            <h2 id="4.4">4.4 Sistemas de Memoria Distribuida: Multiprocesadores</h2> <hr>
            <h4> <i>Multicomputadores</i> </h4>
            <p class="text">En estos sistemas la memoria se encuentra distribuida y no compartida como en los sistemas multiprocesador. Los computadores se comunican a 
            través de paso de mensajes, ya que éstos sólo tienen acceso directo a su memoria local y no a las memorias del resto de procesadores.</p><p><br></p>
            <p class="text">La transferencia de los datos se realiza a través de la red de interconexión que conecta un subconjunto de procesadores con 
            otro subconjunto. La transferencia de unos procesadores a otros se realiza por tanto por múltiples transferencias entre procesadores conectados dependiendo 
            del establecimiento de dicha red.</p><p><br></p>
            <p class="text">Caracteristicas<ul class="indt"><li>La memoria es privada (es decir, cada procesador tiene un mapa de direcciones propio que no es 
            accesible directamente a los demás).</li><li>Los nodos colaboran para resolver juntos un mismo problema (ejecutar la misma aplicación).</li><li>En un multicomputador, 
            cada nodo es una computadora clásica.</li><liLa compartición de datos es explícita, ya que el acceso a datos comunes es por paso de mensajes.</li></ul> </p><p><br></p>
            
            <h1 id="4.4.1">4.4.1 Redes de Interconexión Estáticas</h1>
            <p class="text">utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje 
            no va dirigido al nodo receptor lo reenvía a otro por alguno de sus enlaces de salida siguiendo un protocolo de encaminamiento.</p><p><br></p>
            <h4> <i>Propiedades más significativas</i> </h4>
            
            <h2 id="4.5">4.5 Casos de Estudio </h2> <hr>
            <h4> <i>Nvidia</i> </h4>
            <p class="text">es una empresa que diseña y fabrica tarjetas gráficas, procesadores y sistemas de computación de alto rendimiento. La tecnología CUDA de NVIDIA permite 
            la computación paralela en sus tarjetas gráficas, lo que las hace ideales para aplicaciones como la inteligencia artificial, la simulación y el procesamiento 
            de imágenes</p><p><br></p>
            <h4> <i>Amazon web Services</i> </h4>
            <p class="text">es un servicio de computación en la nube que ofrece una amplia variedad de opciones de computación paralela, incluyendo Amazon EC2, que permite el uso 
            de múltiples instancias para procesamiento paralelo de grandes conjuntos de datos.</p><p><br></p>
            <h4> <i>Google Cloud Platform</i> </h4>
            <p class="text"> utiliza la computación paralela para procesar grandes cantidades de datos. Google también ha desarrollado su propio procesador de inteligencia 
            artificial llamado TPU (Tensor Processing Unit), que utiliza la computación paralela para acelerar el entrenamiento de redes neuronales.</p><p><br></p>
            <p align="center"><img src="https://www.muycomputer.com/wp-content/uploads/procesador-en-2019.jpg"><br></p>
            


            